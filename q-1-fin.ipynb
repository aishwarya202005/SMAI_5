{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Image,display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "# import dill\n",
    "import matplotlib.pyplot as plt  \n",
    "import pandas as pd\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "import math\n",
    "import sys\n",
    "from scipy.linalg import svd\n",
    "\n",
    "# # Read dataset to pandas dataframe\n",
    "# dataset = pd.read_csv('/home/aishwarya/CSIS/SMAI/SMAI_assig/a-5/codes/data.csv')\n",
    "# dataset=dataset.iloc[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "loc='/home/aishwarya/CSIS/SMAI/SMAI_assig/asig_2/RobotDataset/Robot1'\n",
    "dataset = pd.read_csv(loc,sep=' ') \n",
    "dataset.columns= ['Nan','target', 'c2', 'c3', 'c4','c5','c6','c7','id']\n",
    "\n",
    "dataset = dataset.drop('id', 1)\n",
    "dataset=dataset.dropna(axis=1)\n",
    "\n",
    "#moving target to end\n",
    "dataset=dataset[['c2', 'c3', 'c4','c5','c6','c7','target']]\n",
    "\n",
    "\n",
    "train, validate = np.split(dataset, [int(.8*len(dataset))]) #for sequential data\n",
    "# train, validate = np.split(dataset.sample(frac=1), [int(.8*len(dataset))]) # for random \n",
    "\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def prepare_data_X_Y(data1):\n",
    "    X= data1.iloc[:,:-1].values\n",
    "    Y= data1.iloc[:,-1].values\n",
    "    return X,Y\n",
    "    \n",
    "x_train,Y_train=prepare_data_X_Y(train)\n",
    "x_validate,y_validate=prepare_data_X_Y(validate)\n",
    "\n",
    "# X=dataset1\n",
    "# X=(X - dataset.mean().values)/dataset.std().values\n",
    "# type(X)\n",
    "# X\n",
    "# x_train\n",
    "#Xor data\n",
    "XORdata=np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]])\n",
    "# X=XORdata[:,0:2]\n",
    "# y=XORdata[:,-1]\n",
    "\n",
    "X=x_train\n",
    "y=Y_train\n",
    "# len(X[0])\n",
    "# x_validate[3]\n",
    "ys=[3,5,3,2,3]\n",
    "print len(np.unique(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_network(net):\n",
    "    for i,layer in enumerate(net,1):\n",
    "        print(\"Layer {} \".format(i))\n",
    "        for j,neuron in enumerate(layer,1):\n",
    "            print(\"neuron {} :\".format(j),neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(input_neurons,hidden_neurons,output_neurons,n_hidden_layers):\n",
    "    weight_netwrk=[]       \n",
    "    for i in range(n_hidden_layers):\n",
    "        if i!=0:\n",
    "            l=len(weight_netwrk[-1])\n",
    "            input_neurons=l\n",
    "            \n",
    "        hidden_layer = [ { 'weights': np.random.uniform(size=input_neurons)} for i in range(hidden_neurons) ]\n",
    "        weight_netwrk.append(hidden_layer)\n",
    "    \n",
    "    output_layer = [ { 'weights': np.random.uniform(size=hidden_neurons)} for i in range(output_neurons)]\n",
    "    weight_netwrk.append(output_layer)\n",
    "    \n",
    "    return weight_netwrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_sigmoid(sum):\n",
    "    return (1/(1+np.exp(-sum)))\n",
    "\n",
    "def activate_tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def activate_ReLU(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def d_tanh(x):\n",
    "    return 1. - x * x\n",
    "\n",
    "def d_ReLU(x):\n",
    "    return 1. * (x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter number of hidden layers: 1\n",
      "enter activation function: sigmoid\n",
      "enter loss function: MSE\n"
     ]
    }
   ],
   "source": [
    "input_neurons=len(X[0])\n",
    "hidden_neurons=input_neurons+1\n",
    "output_neurons=len(np.unique(y))\n",
    "\n",
    "n_hidden_layers=int(raw_input(\"enter number of hidden layers: \"))\n",
    "# act_func=\"sigmoid\"\n",
    "act_func=raw_input(\"enter activation function: \")\n",
    "# loss_func=\"MSE\"\n",
    "loss_func=raw_input(\"enter loss function: \")\n",
    "net=initialize_network(input_neurons,hidden_neurons,output_neurons,n_hidden_layers)\n",
    "\n",
    "# print_network(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation error\n",
    "def negative_log_likelihood(self):\n",
    "    sigmoid_activation = softmax(numpy.dot(self.x, self.W) + self.b)\n",
    "    cross_entropy = - numpy.mean(numpy.sum(self.y * numpy.log(sigmoid_activation) +(1 - self.y) * numpy.log(1 - sigmoid_activation), axis=1))\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(wgt_net,inputs,act_func):\n",
    "    cur_row=inputs\n",
    "    for layer in wgt_net:\n",
    "#     i=0\n",
    "#     while i<len(net):\n",
    "#         print 'layr-'\n",
    "#         print net[i]\n",
    "#         layer=net[i]\n",
    "        prev_input=np.array([])\n",
    "        for neuron in layer:\n",
    "            sum=neuron['weights'].T.dot(cur_row)\n",
    "            \n",
    "            if act_func==\"sigmoid\":\n",
    "                result=activate_sigmoid(sum)\n",
    "            elif act_func==\"relu\":\n",
    "                result=activate_ReLU(sum)\n",
    "            elif act_func==\"tanh\":\n",
    "                result=activate_tanh(sum)\n",
    "                \n",
    "            neuron['result']=result\n",
    "            \n",
    "            prev_input=np.append(prev_input,[result])\n",
    "            \n",
    "        cur_row =prev_input\n",
    "#         i+=1\n",
    "    \n",
    "    return cur_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_sigmoid(output):\n",
    "    return output*(1.0-output)\n",
    "\n",
    "# expand\n",
    "def cross_entropy(predictions, targets, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Returns: scalar\n",
    "    \"\"\"\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets*np.log(predictions+1e-9))/N\n",
    "    return ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(wgt_net,row,expected,act_func):\n",
    "    length=len(wgt_net)\n",
    "    for i in reversed(range(length)):\n",
    "        layer=wgt_net[i]\n",
    "        layr_len=len(layer)\n",
    "        errors=np.array([])\n",
    "        if i==length-1:\n",
    "            results=[neuron['result'] for neuron in layer]\n",
    "            res=np.array(results) \n",
    "            errors = expected-res\n",
    "        else:\n",
    "            for j in range(layr_len):\n",
    "                herror=0\n",
    "                nextlayer=wgt_net[i+1]\n",
    "                for neuron in nextlayer:\n",
    "                    herror= herror+(neuron['weights'][j]*neuron['delta'])\n",
    "                    \n",
    "                errors=np.append(errors,[herror])\n",
    "        j=0\n",
    "        while j<layr_len:            \n",
    "            neuron=layer[j]\n",
    "            if act_func==\"sigmoid\":\n",
    "                neuron['delta']=errors[j]*d_sigmoid(neuron['result'])\n",
    "            elif act_func==\"relu\":\n",
    "                neuron['delta']=errors[j]*d_ReLU(neuron['result'])\n",
    "            elif act_func==\"tanh\":\n",
    "                neuron['delta']=errors[j]*d_tanh(neuron['result'])\n",
    "            j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWeights(net,input_layr,lrate):\n",
    "    i=0\n",
    "    while i<len(net):\n",
    "#     for i in range(len(net)):\n",
    "        inputs = input_layr\n",
    "        if i!=0:\n",
    "            inputs=[neuron['result'] for neuron in net[i-1]]\n",
    "\n",
    "        for neuron in net[i]:\n",
    "            j=0\n",
    "            while j<len(inputs):\n",
    "                neuron['weights'][j]+=lrate*neuron['delta']*inputs[j]\n",
    "                j+=1\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net,row,act_func):\n",
    "    ans=forward_propagation(net,row,act_func)\n",
    "    return ans\n",
    "\n",
    "def new_weight(net,lrate,row):\n",
    "    updateWeights(net,row,lrate)  \n",
    "\n",
    "\n",
    "def back_prop(net,row,expected,act_func):\n",
    "    back_propagation(net,row,expected,act_func)\n",
    "    \n",
    "def training(net, epochs,lrate,n_outputs,act_func,loss_func):\n",
    "    errors_list=list()\n",
    "    epoc_list=[]\n",
    "    for epoch in range(epochs):\n",
    "        sum_error=0\n",
    "        for i,row in enumerate(X):\n",
    "            \n",
    "            expected=[0.0 for i in range(n_outputs)]\n",
    "            expected[y[i]]=1\n",
    "            \n",
    "            outputs=evaluate(net,row,act_func)\n",
    "            \n",
    "            if loss_func==\"MSE\":\n",
    "                sum_error+=sum([(expected[j]-outputs[j])**2 for j in range(len(expected))])\n",
    "            else:\n",
    "                sum_error=cross_entropy(outputs,expected)\n",
    "                \n",
    "            back_prop(net,row,expected,act_func)\n",
    "            new_weight(net,lrate,row)\n",
    "#             back_propagation(net,row,expected)\n",
    "#             updateWeights(net,row,lrate)\n",
    "\n",
    "        if epoch%100 ==0:\n",
    "            print('>epoch=%d,error=%.3f'%(epoch,sum_error))\n",
    "            epoc_list.append(epoch)\n",
    "            errors_list.append(sum_error)\n",
    "    return errors_list,epoc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0,error=88.531\n",
      ">epoch=100,error=0.026\n",
      ">epoch=200,error=0.014\n",
      ">epoch=300,error=0.009\n",
      ">epoch=400,error=0.007\n",
      ">epoch=500,error=0.006\n",
      ">epoch=600,error=0.005\n",
      ">epoch=700,error=0.004\n",
      ">epoch=800,error=0.004\n",
      ">epoch=900,error=0.003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "errors_list,epoc_list=training(net,1000, 0.05,output_neurons,act_func,loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoc_list,errors_list)\n",
    "plt.ylabel('error')\n",
    "plt.xlabel(\"epochs in 10000's\")\n",
    "plt.title('hay')\n",
    "fname=\"NN_errors_wrt_\"+act_func+\"_\"+loss_func+\"_.png\"\n",
    "plt.savefig(fname)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "def predict(network, row,act_func):\n",
    "    outputs = forward_propagation(net, row,act_func)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred- [ 0.00388196  0.99615894]\n",
      "pred- [ 0.00374057  0.99635405]\n",
      "pred- [ 0.00389736  0.9961599 ]\n",
      "pred- [ 0.00384806  0.99622139]\n",
      "pred- [ 0.00375096  0.99634455]\n",
      "pred- [ 0.00383444  0.99621226]\n",
      "pred- [ 0.00377488  0.9963044 ]\n",
      "pred- [ 0.00373253  0.99636075]\n",
      "pred- [ 0.0038514   0.99618898]\n",
      "pred- [ 0.00378415  0.99629355]\n",
      "pred- [ 0.00372699  0.99636723]\n",
      "pred- [ 0.00373251  0.99635805]\n",
      "pred- [ 0.00372279  0.99637074]\n",
      "pred- [ 0.00378018  0.99627213]\n",
      "pred- [ 0.00375892  0.99631558]\n",
      "pred- [ 0.00374403  0.99633605]\n",
      "pred- [ 0.00371964  0.99637346]\n",
      "pred- [ 0.00379937  0.9962633 ]\n",
      "pred- [ 0.00372712  0.9963661 ]\n",
      "pred- [ 0.00372541  0.99636868]\n",
      "pred- [ 0.00371928  0.99637534]\n",
      "pred- [ 0.0037533   0.99631616]\n",
      "pred- [ 0.00373023  0.99635591]\n",
      "pred- [ 0.00371966  0.99637231]\n",
      "pred- [ 0.00371449  0.99637942]\n",
      "accuracy= 84\n"
     ]
    }
   ],
   "source": [
    "pred_y=[]\n",
    "for i in range(len(validate)):    \n",
    "    pred=predict(net,x_validate[i],act_func)\n",
    "    output=np.argmax(pred)\n",
    "    print 'pred-',pred\n",
    "    pred_y.append(output)\n",
    "        \n",
    "cor=0\n",
    "for i in range(len(validate)):\n",
    "    if y_validate[i]==pred_y[i]:\n",
    "        cor+=1\n",
    "\n",
    "accuracy=cor*100/len(validate)\n",
    "# print 'pred_y=',pred_y\n",
    "print 'accuracy=', accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansTest = pd.DataFrame(pred_y)\n",
    "ansTest.to_csv('2018202005_prediction.csv', index=False)\n",
    "\n",
    "# from google.colab import files\n",
    "# files.download(\"2018202015_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
